{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT ALL THE NECESSARY SPARK LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import StructType,StructField,DateType,TimestampType,StringType,IntegerType,DecimalType\n",
    "from pyspark.sql.functions import year, month, dayofmonth,to_timestamp,to_date,split,substring,col,when\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import lit,split,concat,ceil\n",
    "import logging\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING A SPARK SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a spark session\n",
    "spark = SparkSession.builder.enableHiveSupport().appName(\"Analytical_ETL_spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING AND PROCESSING DATA FOR CURRENT DATE 2021-04-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the current date (4/18/2020) to a dataframe (df)\n",
    "df = spark.read.parquet(\"hdfs://localhost:8020/stock/trade/partition=2021-04-18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tmp_trade_moving_avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the moving average for last 30 minutes\n",
    "mov_avg_df = spark.sql(\"\"\"select symbol, exchange, trade_dt,event_tm, event_seq_nb, trade_pr,\n",
    "                        AVG(trade_pr) OVER(PARTITION BY (symbol) ORDER BY CAST(event_tm AS timestamp) \n",
    "                        RANGE BETWEEN INTERVAL 30 MINUTES PRECEDING AND CURRENT ROW) as mov_avg_pr\n",
    "                        from tmp_trade_moving_avg\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DROP HIVE TABLE IF EXISTS\n",
    "spark.sql(\"DROP TABLE IF EXISTS temp_trade_moving_avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data frame as table in hive\n",
    "mov_avg_df.write.saveAsTable(\"temp_trade_moving_avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+--------------------+------------+--------+----------+\n",
      "|symbol|exchange|  trade_dt|            event_tm|event_seq_nb|trade_pr|mov_avg_pr|\n",
      "+------+--------+----------+--------------------+------------+--------+----------+\n",
      "|  SYMA|  NASDAQ|2021-04-18|2021-04-18 10:37:...|          10|      15|      15.0|\n",
      "|  SYMA|  NASDAQ|2021-04-18|2021-04-18 10:49:...|          10|      15|      15.0|\n",
      "|  SYMA|  NASDAQ|2021-04-18|2021-04-18 11:56:...|          20|      25|      25.0|\n",
      "|  SYMA|  NASDAQ|2021-04-18|2021-04-18 12:00:...|          20|      25|      25.0|\n",
      "|  SYMA|  NASDAQ|2021-04-18|2021-04-18 13:09:...|          30|      35|      35.0|\n",
      "+------+--------+----------+--------------------+------------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mov_avg_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING AND PROCESSING DATA FOR PREVIOUS DATE 2021-04-17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the previous date (4/17/2020) to a dataframe (df)\n",
    "df = spark.read.parquet(\"hdfs://localhost:8020/stock/trade/partition=2021-04-17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"temp_last_trade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the moving average for last 30 minutes\n",
    "last_pr_df = spark.sql(\"\"\"select symbol, trade_dt,exchange, event_tm, event_seq_nb, trade_pr,\n",
    "                        AVG(trade_pr) OVER(PARTITION BY (symbol) ORDER BY CAST(event_tm AS timestamp) \n",
    "                        RANGE BETWEEN INTERVAL 30 MINUTES PRECEDING AND CURRENT ROW) as last_pr\n",
    "                        from temp_last_trade\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DROP HIVE TABLE IF EXISTS\n",
    "spark.sql(\"DROP TABLE IF EXISTS temp_last_trade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data frame as table in hive\n",
    "last_pr_df.write.saveAsTable(\"temp_last_trade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+--------------------+------------+--------+-------+\n",
      "|symbol|  trade_dt|exchange|            event_tm|event_seq_nb|trade_pr|last_pr|\n",
      "+------+----------+--------+--------------------+------------+--------+-------+\n",
      "|  SYMA|2021-04-17|  NASDAQ|2021-04-17 10:37:...|          10|      15|   15.0|\n",
      "|  SYMA|2021-04-17|  NASDAQ|2021-04-17 10:49:...|          10|      15|   15.0|\n",
      "|  SYMA|2021-04-17|  NASDAQ|2021-04-17 11:56:...|          20|      25|   25.0|\n",
      "|  SYMA|2021-04-17|  NASDAQ|2021-04-17 12:00:...|          20|      25|   25.0|\n",
      "|  SYMA|2021-04-17|  NASDAQ|2021-04-17 13:09:...|          30|      35|   35.0|\n",
      "+------+----------+--------+--------------------+------------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "last_pr_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING QUOTES DATA FOR 2021-04-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = spark.read.parquet(\"hdfs://localhost:8020/stock/partition=Q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes.createOrReplaceTempView(\"quotes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNION QUOTES AND TRADES INTO A SINGLE UNION VIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_union = spark.sql(\"\"\"\n",
    "SELECT trade_dt,rec_type,symbol,event_tm,event_seq_nb,exchange,bid_pr,bid_size,ask_pr,\n",
    "ask_size,null as trade_pr,null as mov_avg_pr FROM quotes\n",
    "UNION\n",
    "SELECT trade_dt,\"T\" as rec_type,symbol,event_tm,event_seq_nb,exchange,null as bid_pr,null as bid_size,null as ask_pr,\n",
    "null as ask_size,trade_pr,mov_avg_pr FROM temp_trade_moving_avg\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_union.createOrReplaceTempView(\"quote_union\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POPULATE THE LAST NOT NULL TRADE PRICE AND MOVING AVERAGE PRICE FROM TRADE RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_union_update = spark.sql(\"\"\"\n",
    "select *,\n",
    "last_value(trade_pr,true) OVER(PARTITION BY (symbol) \n",
    "ORDER BY CAST(event_tm AS timestamp) DESC) as last_trade_pr,\n",
    "last_value(mov_avg_pr,true) OVER(PARTITION BY (symbol) \n",
    "ORDER BY CAST(event_tm AS timestamp) DESC) as last_mov_avg_pr\n",
    "from quote_union\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_union_update.createOrReplaceTempView(\"quote_union_update\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FILTER FOR QUOTE RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_update = spark.sql(\"\"\"\n",
    "select trade_dt, symbol, event_tm, event_seq_nb, exchange,\n",
    "bid_pr, bid_size, ask_pr, ask_size, last_trade_pr, last_mov_avg_pr\n",
    "from quote_union_update\n",
    "where rec_type = 'Q'\n",
    "\"\"\")\n",
    "quote_update.createOrReplaceTempView(\"quote_update\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join With Table temp_last_trade To Get The Prior Day Close Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_final = spark.sql(\"\"\"\n",
    "select trade_dt, A.symbol, event_tm, event_seq_nb, exchange,\n",
    "bid_pr, bid_size, ask_pr, ask_size, last_trade_pr, last_mov_avg_pr,\n",
    "bid_pr - close_pr as bid_pr_mv, ask_pr - close_pr as ask_pr_mv\n",
    "from quote_update A LEFT OUTER JOIN (select distinct symbol,last_pr as close_pr from temp_last_trade) B\n",
    "on A.symbol = B.symbol\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+------------+--------+------+--------+------+--------+-------------+---------------+---------+---------+\n",
      "|  trade_dt|symbol|            event_tm|event_seq_nb|exchange|bid_pr|bid_size|ask_pr|ask_size|last_trade_pr|last_mov_avg_pr|bid_pr_mv|ask_pr_mv|\n",
      "+----------+------+--------------------+------------+--------+------+--------+------+--------+-------------+---------------+---------+---------+\n",
      "|2021-04-18|  SYMA|2021-04-18 21:51:...|          99|  NASDAQ|    77|     100|    77|     100|          105|          105.0|     12.0|     12.0|\n",
      "|2021-04-18|  SYMA|2021-04-18 21:51:...|          99|  NASDAQ|    77|     100|    77|     100|          105|          105.0|     62.0|     62.0|\n",
      "|2021-04-18|  SYMA|2021-04-18 21:51:...|          99|  NASDAQ|    77|     100|    77|     100|          105|          105.0|     -8.0|     -8.0|\n",
      "|2021-04-18|  SYMA|2021-04-18 21:51:...|          99|  NASDAQ|    77|     100|    77|     100|          105|          105.0|     42.0|     42.0|\n",
      "|2021-04-18|  SYMA|2021-04-18 21:51:...|          99|  NASDAQ|    77|     100|    77|     100|          105|          105.0|     52.0|     52.0|\n",
      "+----------+------+--------------------+------------+--------+------+--------+------+--------+-------------+---------------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quote_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_date = \"2021-04-18\"\n",
    "quote_final.write.mode(\"overwrite\").parquet(\"hdfs://localhost:8020/stock/quote-trade-analytical/date={}\".format(trade_date))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
